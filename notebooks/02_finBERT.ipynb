{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from tqdm import tqdm \n",
    "\n",
    "INPUT_FILE = '/kaggle/input/spy-news/SPY_news_only.csv'\n",
    "OUTPUT_FILE = '/kaggle/working/spy_news_sentiment.csv'\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 0 \n",
    "    print(f\" GPU Attiva: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "df = df.dropna(subset=['Article_title'])\n",
    "titles = df['Article_title'].tolist()\n",
    "print(f\"Totale titoli da analizzare: {len(titles)}\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device, return_all_scores=True)\n",
    "\n",
    "print(\"Inizio analisi del sentiment\")\n",
    "\n",
    "results = []\n",
    "batch_size = 32  \n",
    "\n",
    "for i in tqdm(range(0, len(titles), batch_size)):\n",
    "    batch = titles[i:i+batch_size]\n",
    "    batch_results = nlp(batch)\n",
    "    results.extend(batch_results)\n",
    "\n",
    "\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "for res in results:\n",
    "    scores = {item['label']: item['score'] for item in res}\n",
    "    \n",
    "    positive_scores.append(scores.get('positive', 0))\n",
    "    negative_scores.append(scores.get('negative', 0))\n",
    "    neutral_scores.append(scores.get('neutral', 0))\n",
    "\n",
    "df['sentiment_positive'] = positive_scores\n",
    "df['sentiment_negative'] = negative_scores\n",
    "df['sentiment_neutral'] = neutral_scores\n",
    "\n",
    "df['sentiment_label'] = df[['sentiment_positive', 'sentiment_negative', 'sentiment_neutral']].idxmax(axis=1).str.replace('sentiment_', '')\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(df[['Article_title', 'sentiment_label', 'sentiment_positive', 'sentiment_negative']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2232947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from tqdm import tqdm \n",
    "\n",
    "INPUT_FILE = '/kaggle/input/spy-news/SPY_news_only.csv'\n",
    "OUTPUT_FILE = '/kaggle/working/spy_news_sentiment_lexrank_summary.csv'\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 0 \n",
    "    print(f\"GPU Attiva: {torch.cuda.get_device_name(0)}\")\n",
    "col = 'Lexrank_summary'\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "df = df.dropna(subset=[col])\n",
    "titles = df[col].tolist()\n",
    "\n",
    "print(f\"Totale istanze da analizzare: {len(titles)}\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"sentiment-analysis\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    device=device, \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def analyze_long_text(text, max_length=500):\n",
    "\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    \n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    \n",
    "    if len(tokens) <= max_length:\n",
    "        try:\n",
    "            return nlp(text)[0]\n",
    "        except:\n",
    "            # Fallback per testi vuoti\n",
    "            return [\n",
    "                {'label': 'positive', 'score': 0.33},\n",
    "                {'label': 'negative', 'score': 0.33},\n",
    "                {'label': 'neutral', 'score': 0.34}\n",
    "            ]\n",
    "    \n",
    "    overlap = max_length // 8\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(tokens), max_length - overlap):\n",
    "        chunk_tokens = tokens[i:i+max_length]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
    "        if chunk_text.strip():  \n",
    "            chunks.append(chunk_text)\n",
    "    \n",
    "    if not chunks:\n",
    "        return [\n",
    "            {'label': 'positive', 'score': 0.33},\n",
    "            {'label': 'negative', 'score': 0.33},\n",
    "            {'label': 'neutral', 'score': 0.34}\n",
    "        ]\n",
    "    \n",
    "    all_scores = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            result = nlp(chunk)[0]\n",
    "            all_scores.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nell'analisi di un chunk: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_scores:\n",
    "        return [\n",
    "            {'label': 'positive', 'score': 0.33},\n",
    "            {'label': 'negative', 'score': 0.33},\n",
    "            {'label': 'neutral', 'score': 0.34}\n",
    "        ]\n",
    "    \n",
    "    avg_scores = {}\n",
    "    for label in ['positive', 'negative', 'neutral']:\n",
    "        scores_for_label = [\n",
    "            next((item['score'] for item in scores if item['label'] == label), 0)\n",
    "            for scores in all_scores\n",
    "        ]\n",
    "        avg_scores[label] = np.mean(scores_for_label)\n",
    "    \n",
    "    return [{'label': k, 'score': v} for k, v in avg_scores.items()]\n",
    "\n",
    "print(\"Inizio analisi del sentiment con sliding window\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for text in tqdm(titles, desc=\"Analisi sentiment\"):\n",
    "    result = analyze_long_text(text)\n",
    "    results.append(result)\n",
    "\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "neutral_scores = []\n",
    "\n",
    "for res in results:\n",
    "    scores = {item['label']: item['score'] for item in res}\n",
    "    positive_scores.append(scores.get('positive', 0))\n",
    "    negative_scores.append(scores.get('negative', 0))\n",
    "    neutral_scores.append(scores.get('neutral', 0))\n",
    "\n",
    "df['sentiment_positive'] = positive_scores\n",
    "df['sentiment_negative'] = negative_scores\n",
    "df['sentiment_neutral'] = neutral_scores\n",
    "df['sentiment_label'] = df[['sentiment_positive', 'sentiment_negative', 'sentiment_neutral']].idxmax(axis=1).str.replace('sentiment_', '')\n",
    "\n",
    "df['text_length'] = df[col].apply(lambda x: len(tokenizer.encode(str(x), add_special_tokens=False)) if pd.notna(x) else 0)\n",
    "df['num_chunks'] = df['text_length'].apply(lambda x: max(1, int(np.ceil(x / 510))))\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"\\n=== ANALISI COMPLETATA ===\")\n",
    "print(f\"File salvato in: {OUTPUT_FILE}\")\n",
    "print(\"\\n=== STATISTICHE ===\")\n",
    "print(f\"Testi analizzati: {len(df)}\")\n",
    "print(\"\\n=== DISTRIBUZIONE SENTIMENT ===\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(\"\\n=== ESEMPI ===\")\n",
    "print(df[['Lsa_summary', 'sentiment_label', 'sentiment_positive', 'sentiment_negative', 'text_length', 'num_chunks']].head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
